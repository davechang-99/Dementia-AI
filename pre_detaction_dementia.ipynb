{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davechang-99/Dementia-AI/blob/main/pre_detaction_dementia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 셀 1: 환경 설정 및 라이브러리 설치"
      ],
      "metadata": {
        "id": "GijtG-R_CmtB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSIYfrERyhO9"
      },
      "outputs": [],
      "source": [
        "# 이 셀은 필요한 Python 라이브러리를 설치하고, 변경사항을 적용하기 위해 런타임을 재시작합니다.\n",
        "\n",
        "# 필요한 라이브러리 설치\n",
        "!pip install transformers==4.40.1\n",
        "!pip install torchaudio==2.1.2\n",
        "!pip install librosa==0.10.1\n",
        "!pip install soundfile==0.12.1\n",
        "!pip install datasets==2.20.0\n",
        "!pip install scikit-learn==1.4.2 # 안정적인 버전으로 변경\n",
        "!pip install numpy==1.26.4 # 안정적인 버전으로 변경\n",
        "!pip install xgboost==2.0.3\n",
        "\n",
        "# 런타임 재시작 (설치된 패키지 적용을 위함)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 셀 2: 구글 드라이브 마운트 및 라이브러리 임포트"
      ],
      "metadata": {
        "id": "7slAJQqFCqgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 런타임 재시작 후, 이 셀을 다시 실행하여 필요한 라이브러리를 임포트하고 구글 드라이브에 연결합니다.\n",
        "\n",
        "# 필요한 라이브러리 임포트\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split # 데이터 분할을 위해 추가\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "from google.colab import drive\n",
        "\n",
        "# 구글 드라이브 마운트\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "id": "U8fjMDGYyokG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 셀 3: 설정값 및 데이터 경로 함수 정의"
      ],
      "metadata": {
        "id": "DtmxxRJSCxms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련에 필요한 전역 변수를 설정하고, 오디오 파일 경로를 수집하는 함수를 정의합니다.\n",
        "\n",
        "# 설정값\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "DATASET_ROOT = \"/content/gdrive/My Drive/DATASET_en\"\n",
        "TEST_FILE_PATH = \"/content/gdrive/My Drive/test_results.txt\"\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "# 스펙트로그램의 고정된 길이를 설정하여 패딩/자르기를 수행합니다.\n",
        "MAX_SPEC_LENGTH = 256\n",
        "\n",
        "def collect_all_data(data_dir):\n",
        "    \"\"\"\n",
        "    지정된 디렉토리의 모든 오디오 파일 경로와 레이블을 수집합니다.\n",
        "    (train, validation 폴더가 없는 구조에 맞게 수정됨)\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "    labels = []\n",
        "    normal_path = os.path.join(data_dir, \"Normal\")\n",
        "    dementia_path = os.path.join(data_dir, \"Dementia\")\n",
        "\n",
        "    print(f\"Checking for Normal data in: {normal_path}\")\n",
        "    if os.path.exists(normal_path):\n",
        "        for file_name in os.listdir(normal_path):\n",
        "            if file_name.endswith('.wav'):\n",
        "                paths.append(os.path.join(normal_path, file_name))\n",
        "                labels.append(0)\n",
        "\n",
        "    print(f\"Checking for Dementia data in: {dementia_path}\")\n",
        "    if os.path.exists(dementia_path):\n",
        "        for file_name in os.listdir(dementia_path):\n",
        "            if file_name.endswith('.wav'):\n",
        "                paths.append(os.path.join(dementia_path, file_name))\n",
        "                labels.append(1)\n",
        "\n",
        "    print(f\"Found {len(paths)} files in {data_dir}\")\n",
        "    return paths, labels\n",
        "\n",
        "def get_test_data_paths(data_dir):\n",
        "    \"\"\"\n",
        "    테스트 폴더에서 오디오 파일 경로를 수집합니다.\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "    test_path = os.path.join(data_dir, \"test\")\n",
        "    if os.path.exists(test_path):\n",
        "        for file_name in os.listdir(test_path):\n",
        "            if file_name.endswith('.wav'):\n",
        "                paths.append(os.path.join(test_path, file_name))\n",
        "\n",
        "    print(f\"Found {len(paths)} files in {test_path}\")\n",
        "    return paths\n",
        "\n",
        "# 전체 데이터 수집 및 훈련/검증 데이터로 분할\n",
        "all_paths, all_labels = collect_all_data(DATASET_ROOT)\n",
        "if len(all_paths) > 0:\n",
        "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "        all_paths, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
        "    )\n",
        "    print(f\"Split data: {len(train_paths)} for training, {len(val_paths)} for validation.\")\n",
        "else:\n",
        "    train_paths, val_paths, train_labels, val_labels = [], [], [], []\n",
        "    print(\"Warning: No data found to perform train-validation split.\")\n",
        "\n",
        "test_paths = get_test_data_paths(DATASET_ROOT)\n"
      ],
      "metadata": {
        "id": "1rLQclqNyoqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 셀 4: 데이터셋 클래스 정의 (CNN, ViT용)"
      ],
      "metadata": {
        "id": "5URtf6uLC1NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 오디오 파일을 멜 스펙트로그램으로 변환하여 훈련에 사용될 PyTorch 데이터셋 클래스를 정의합니다.\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    \"\"\"오디오 파일을 멜 스펙트로그램으로 변환하여 모델 입력으로 사용합니다.\"\"\"\n",
        "    def __init__(self, file_paths, labels, feature_extractor=None, max_length=MAX_SPEC_LENGTH):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        audio, sr = librosa.load(file_path, sr=16000)\n",
        "\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=8000)\n",
        "        mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
        "\n",
        "        # 멜 스펙트로그램 길이를 고정\n",
        "        if mel_spectrogram.shape[1] > self.max_length:\n",
        "            mel_spectrogram = mel_spectrogram[:, :self.max_length]\n",
        "        else:\n",
        "            padding_width = self.max_length - mel_spectrogram.shape[1]\n",
        "            mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, padding_width)), mode='constant')\n",
        "\n",
        "       # ViT 입력 형식에 맞게 3채널로 변환\n",
        "        if self.feature_extractor:\n",
        "            mel_spectrogram_3channel = np.stack([mel_spectrogram, mel_spectrogram, mel_spectrogram], axis=-1)\n",
        "\n",
        "            # === 수정 시작 지점 ===\n",
        "            # ViT 모델에 입력하기 전에 멜 스펙트로그램을 정규화합니다.\n",
        "            # 정규화는 멜 스펙트로그램의 픽셀 값 범위를 [0, 1]로 조정합니다.\n",
        "            # 이 과정은 ViTFeatureExtractor의 internal normalization과 호환됩니다.\n",
        "            # min-max 정규화\n",
        "            min_val = np.min(mel_spectrogram_3channel)\n",
        "            max_val = np.max(mel_spectrogram_3channel)\n",
        "            mel_spectrogram_normalized = (mel_spectrogram_3channel - min_val) / (max_val - min_val)\n",
        "            mel_spectrogram_normalized = np.array(mel_spectrogram_normalized * 255, dtype=np.uint8)\n",
        "\n",
        "            inputs = self.feature_extractor(images=mel_spectrogram_normalized, return_tensors=\"pt\")\n",
        "            # === 수정 끝 지점 ===\n",
        "\n",
        "            inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
        "            inputs['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "            return inputs\n",
        "\n",
        "\n",
        "        # CNN 입력 형식 (단일 채널)\n",
        "        else:\n",
        "            mel_spectrogram = torch.tensor(mel_spectrogram, dtype=torch.float32).unsqueeze(0)\n",
        "            return mel_spectrogram, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "sQV8IuwV_ZrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 셀 4-1: 멜 스펙트로그램 이미지 저장 (선택 사항)"
      ],
      "metadata": {
        "id": "eWpnGPJuC7jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 셀을 실행하면 훈련 데이터셋의 멜 스펙트로그램 이미지 일부를 `mel_spectrogram_images` 폴더에 저장합니다.\n",
        "# **모델 훈련에는 필요하지 않은 선택적 셀입니다.**\n",
        "\n",
        "def save_mel_spectrogram_as_image(spectrogram, file_path, title=\"Mel Spectrogram\"):\n",
        "    \"\"\"\n",
        "    멜 스펙트로그램을 이미지 파일로 저장합니다.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(spectrogram, y_axis='mel', x_axis='time')\n",
        "    plt.title(title)\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path)\n",
        "    plt.close()\n",
        "\n",
        "# 이미지를 저장할 폴더 생성\n",
        "image_save_dir = \"/content/gdrive/My Drive/mel_spectrogram_images\"\n",
        "os.makedirs(image_save_dir, exist_ok=True)\n",
        "print(f\"Saving sample images to: {image_save_dir}\")\n",
        "\n",
        "# 훈련 데이터셋에서 처음 5개 샘플의 스펙트로그램을 이미지로 저장\n",
        "if len(train_paths) > 0:\n",
        "    sample_dataset = AudioDataset(train_paths[:5], train_labels[:5])\n",
        "    for i in range(len(sample_dataset)):\n",
        "        spec, label = sample_dataset[i]\n",
        "        spec_np = spec.squeeze().numpy()\n",
        "        label_text = \"Dementia\" if label.item() == 1 else \"Normal\"\n",
        "        file_name = f\"sample_{i}_{label_text}.png\"\n",
        "        file_path = os.path.join(image_save_dir, file_name)\n",
        "        save_mel_spectrogram_as_image(spec_np, file_path, title=f\"Sample {i} - {label_text}\")\n",
        "    print(\"5 sample images saved.\")\n",
        "else:\n",
        "    print(\"No training data found, skipping image saving.\")\n"
      ],
      "metadata": {
        "id": "Wgg4EiVIB_2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 셀 5: CNN 모델 정의"
      ],
      "metadata": {
        "id": "XkyGS3uGDAeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 합성곱 신경망(CNN) 모델 아키텍처를 정의합니다.\n",
        "\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    \"\"\"간단한 합성곱 신경망 모델입니다.\"\"\"\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv_layers = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2),\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        # 패딩된 스펙트로그램 크기(128x256)에 맞게 fc_layers 입력 크기 조정\n",
        "        # MaxPool2d 2번 통과 후 크기: (128/2/2) x (256/2/2) = 32 x 64\n",
        "        self.fc_layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(64 * 32 * 64, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yt-IG5NhyowU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#셀 6: 모델 훈련 및 평가 함수"
      ],
      "metadata": {
        "id": "fMLSYYnsDF_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 모델 (CNN, ViT)과 scikit-learn 모델 (RandomForest)을 훈련하고 평가하는 공통 함수를 정의합니다.\n",
        "\n",
        "def train_and_evaluate(model, train_dataloader, val_dataloader, device, model_type):\n",
        "    \"\"\"주어진 모델을 훈련하고 검증 데이터셋으로 평가합니다.\"\"\"\n",
        "\n",
        "    # RandomForest는 별도 훈련 로직 적용\n",
        "    if model_type == \"RandomForest\":\n",
        "        print(\"Training RandomForest started...\")\n",
        "        train_features, train_y = [], []\n",
        "        for x, y in tqdm(train_dataloader, desc=\"Preparing RF training data\"):\n",
        "            train_features.extend(x.reshape(x.shape[0], -1).numpy())\n",
        "            train_y.extend(y.numpy())\n",
        "\n",
        "        val_features, val_y = [], []\n",
        "        for x, y in tqdm(val_dataloader, desc=\"Preparing RF validation data\"):\n",
        "            val_features.extend(x.reshape(x.shape[0], -1).numpy())\n",
        "            val_y.extend(y.numpy())\n",
        "\n",
        "        # 수정된 부분: val_y 대신 train_y로 모델을 훈련합니다.\n",
        "        model.fit(train_features, train_y)\n",
        "        preds = model.predict(val_features)\n",
        "        preds_proba = model.predict_proba(val_features)\n",
        "        return val_y, preds, preds_proba\n",
        "\n",
        "    # PyTorch 모델 훈련\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    print(f\"Training {model_type} started...\")\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
        "            if model_type == \"ViT\":\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "                labels = inputs.pop('labels')\n",
        "                outputs = model(**inputs, labels=labels)\n",
        "                loss = outputs.loss\n",
        "            else: # CNN\n",
        "                x, y = batch\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                outputs = model(x)\n",
        "                loss = criterion(outputs, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1} completed. Average Loss: {total_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_dataloader, desc=f\"Evaluating {model_type}\"):\n",
        "            if model_type == \"ViT\":\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "                labels = inputs.pop('labels')\n",
        "                outputs = model(**inputs, labels=labels)\n",
        "                logits = outputs.logits\n",
        "            else: # CNN\n",
        "                x, y = batch\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                outputs = model(x)\n",
        "                logits = outputs\n",
        "\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_true.extend(labels.cpu().numpy() if model_type == \"ViT\" else y.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    return np.array(all_true), np.array(all_preds), np.array(all_probs)\n"
      ],
      "metadata": {
        "id": "0L_EjC6RyozY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  셀 7: 성능 시각화 함수"
      ],
      "metadata": {
        "id": "xdg2nET_DNYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 성능을 혼동 행렬과 ROC 곡선으로 시각화하고, 성능 지표를 반환하는 함수를 정의합니다.\n",
        "\n",
        "def plot_results(y_true, y_pred, y_prob, model_name):\n",
        "    \"\"\"\n",
        "    분류 결과를 시각화하고 성능 지표를 반환합니다.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- {model_name} Results ---\")\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    auc = roc_auc_score(y_true, y_prob[:, 1])\n",
        "\n",
        "    # 혼동 행렬 시각화\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[\"Normal\", \"Dementia\"],\n",
        "                yticklabels=[\"Normal\", \"Dementia\"])\n",
        "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC 곡선 시각화\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {model_name}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    return report, auc"
      ],
      "metadata": {
        "id": "ntg7lXvUyo2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  셀 8: 모델별 훈련 및 평가 실행"
      ],
      "metadata": {
        "id": "hUPjFukhDTI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 셀은 CNN, ViT, RandomForest 모델을 각각 초기화하고, 훈련 및 평가를 수행합니다.\n",
        "\n",
        "# CNN 모델\n",
        "print(\"Initializing CNN Model...\")\n",
        "if not train_paths or not val_paths:\n",
        "    print(\"WARNING: Training or validation data not found. Please check your Google Drive folder structure.\")\n",
        "    cnn_true, cnn_preds, cnn_preds_proba = np.array([]), np.array([]), np.array([[],[]]).T\n",
        "else:\n",
        "    cnn_model = SimpleCNN().to(DEVICE)\n",
        "    cnn_train_dataset = AudioDataset(train_paths, train_labels)\n",
        "    cnn_val_dataset = AudioDataset(val_paths, val_labels)\n",
        "    cnn_train_dataloader = DataLoader(cnn_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    cnn_val_dataloader = DataLoader(cnn_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    cnn_true, cnn_preds, cnn_preds_proba = train_and_evaluate(cnn_model, cnn_train_dataloader, cnn_val_dataloader, DEVICE, \"CNN\")\n",
        "\n",
        "# ViT 모델\n",
        "print(\"\\nInitializing ViT Model...\")\n",
        "if not train_paths or not val_paths:\n",
        "    print(\"WARNING: Training or validation data not found. Please check your Google Drive folder structure.\")\n",
        "    vit_true, vit_preds, vit_preds_proba = np.array([]), np.array([]), np.array([[],[]]).T\n",
        "else:\n",
        "    model_name = \"google/vit-base-patch16-224\"\n",
        "    feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "    vit_model = ViTForImageClassification.from_pretrained(model_name,\n",
        "                                                          num_labels=2,\n",
        "                                                          ignore_mismatched_sizes=True)\n",
        "    vit_model.to(DEVICE)\n",
        "    vit_train_dataset = AudioDataset(train_paths, train_labels, feature_extractor)\n",
        "    vit_val_dataset = AudioDataset(val_paths, val_labels, feature_extractor)\n",
        "    vit_train_dataloader = DataLoader(vit_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    vit_val_dataloader = DataLoader(vit_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    vit_true, vit_preds, vit_preds_proba = train_and_evaluate(vit_model, vit_train_dataloader, vit_val_dataloader, DEVICE, \"ViT\")\n",
        "\n",
        "# RandomForest 모델\n",
        "print(\"\\nInitializing RandomForest Model...\")\n",
        "if not train_paths or not val_paths:\n",
        "    print(\"WARNING: Training or validation data not found. Please check your Google Drive folder structure.\")\n",
        "    rf_true, rf_preds, rf_preds_proba = np.array([]), np.array([]), np.array([[],[]]).T\n",
        "else:\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_train_dataset = AudioDataset(train_paths, train_labels)\n",
        "    rf_val_dataset = AudioDataset(val_paths, val_labels)\n",
        "    rf_train_dataloader = DataLoader(rf_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    rf_val_dataloader = DataLoader(rf_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    rf_true, rf_preds, rf_preds_proba = train_and_evaluate(rf_model, rf_train_dataloader, rf_val_dataloader, \"cpu\", \"RandomForest\")\n"
      ],
      "metadata": {
        "id": "pqFIqONIyo47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 9: 성능 지표 수집 및 비교"
      ],
      "metadata": {
        "id": "RfJLFrBwDYh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련된 각 모델의 성능 지표를 수집하고, 데이터프레임으로 정리하여 비교합니다.\n",
        "\n",
        "# 데이터가 있을 경우에만 성능 평가 실행\n",
        "if len(cnn_true) > 0:\n",
        "    cnn_report, cnn_auc = plot_results(cnn_true, cnn_preds, cnn_preds_proba, \"CNN\")\n",
        "    vit_report, vit_auc = plot_results(vit_true, vit_preds, vit_preds_proba, \"ViT\")\n",
        "    rf_report, rf_auc = plot_results(rf_true, rf_preds, rf_preds_proba, \"RandomForest\")\n",
        "\n",
        "    # 성능 비교 표 생성 및 출력\n",
        "    results_df = pd.DataFrame({\n",
        "        'Model': ['CNN', 'ViT', 'RandomForest'],\n",
        "        'Accuracy': [cnn_report['accuracy'], vit_report['accuracy'], rf_report['accuracy']],\n",
        "        'Precision': [cnn_report['weighted avg']['precision'], vit_report['weighted avg']['precision'], rf_report['weighted avg']['precision']],\n",
        "        'Recall': [cnn_report['weighted avg']['recall'], vit_report['weighted avg']['recall'], rf_report['weighted avg']['recall']],\n",
        "        'F1-Score': [cnn_report['weighted avg']['f1-score'], vit_report['weighted avg']['f1-score'], rf_report['weighted avg']['f1-score']],\n",
        "        'AUC': [cnn_auc, vit_auc, rf_auc]\n",
        "    }).set_index('Model')\n",
        "\n",
        "    print(\"\\n--- Model Performance Comparison ---\")\n",
        "    display(results_df)"
      ],
      "metadata": {
        "id": "HPo1Pt8lzYuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 10: 테스트 데이터 예측 및 결과 저장"
      ],
      "metadata": {
        "id": "XJFWO_CxDhm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 성능이 좋은 모델을 선택하고, `test` 폴더의 오디오 파일을 사용하여 예측을 수행한 뒤, 결과를 `test_results.txt`에 저장합니다.\n",
        "\n",
        "print(\"\\n--- Test Predictions ---\")\n",
        "test_ids = []\n",
        "final_test_preds = []\n",
        "\n",
        "# 데이터가 있을 경우에만 예측 실행\n",
        "if len(test_paths) > 0 and 'results_df' in locals():\n",
        "    # 최적 모델 (예: AUC가 가장 높은 모델) 선택\n",
        "    best_model_name = results_df['AUC'].idxmax()\n",
        "    print(f\"Best performing model based on AUC is: {best_model_name}\")\n",
        "\n",
        "    if best_model_name == \"ViT\":\n",
        "        test_model = vit_model\n",
        "        test_feature_extractor = feature_extractor\n",
        "    elif best_model_name == \"CNN\":\n",
        "        test_model = cnn_model\n",
        "        test_feature_extractor = None\n",
        "    else: # RandomForest\n",
        "        test_model = rf_model\n",
        "        test_feature_extractor = None\n",
        "\n",
        "    # 테스트 데이터셋 클래스 (레이블 없음)\n",
        "    class TestAudioDataset(Dataset):\n",
        "        def __init__(self, file_paths, feature_extractor=None):\n",
        "            self.file_paths = file_paths\n",
        "            self.feature_extractor = feature_extractor\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.file_paths)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            file_path = self.file_paths[idx]\n",
        "            audio, sr = librosa.load(file_path, sr=16000)\n",
        "            mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=8000)\n",
        "            mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
        "\n",
        "            if self.feature_extractor:\n",
        "                mel_spectrogram_3channel = np.stack([mel_spectrogram, mel_spectrogram, mel_spectrogram], axis=-1)\n",
        "\n",
        "                # --- 수정된 코드: ViT 모델 입력 전 정규화 ---\n",
        "                min_val = np.min(mel_spectrogram_3channel)\n",
        "                max_val = np.max(mel_spectrogram_3channel)\n",
        "                mel_spectrogram_normalized = (mel_spectrogram_3channel - min_val) / (max_val - min_val)\n",
        "                mel_spectrogram_normalized = np.array(mel_spectrogram_normalized * 255, dtype=np.uint8)\n",
        "                # ---------------------------------------------\n",
        "\n",
        "                inputs = self.feature_extractor(images=mel_spectrogram_normalized, return_tensors=\"pt\")\n",
        "                return {k: v.squeeze(0) for k, v in inputs.items()}, os.path.basename(file_path)\n",
        "            else: # CNN or RF\n",
        "                mel_spectrogram = torch.tensor(mel_spectrogram, dtype=torch.float32)\n",
        "                return mel_spectrogram, os.path.basename(file_path)\n",
        "\n",
        "    test_dataset = TestAudioDataset(test_paths, test_feature_extractor)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # 테스트 예측 수행\n",
        "    if best_model_name in [\"ViT\", \"CNN\"]:\n",
        "        test_model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, file_names in tqdm(test_dataloader, desc=\"Predicting on test data\"):\n",
        "                test_ids.extend([f.split('.')[0] for f in file_names])\n",
        "                if best_model_name == \"ViT\":\n",
        "                    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "                    outputs = test_model(**inputs)\n",
        "                    logits = outputs.logits\n",
        "                else: # CNN\n",
        "                    inputs = inputs.to(DEVICE)\n",
        "                    outputs = test_model(inputs)\n",
        "                    logits = outputs\n",
        "\n",
        "                predictions = torch.argmax(logits, dim=-1)\n",
        "                final_test_preds.extend(predictions.cpu().numpy())\n",
        "    else: # RandomForest\n",
        "        test_features = []\n",
        "        for x, file_name in tqdm(test_dataloader, desc=\"Preparing RF test data\"):\n",
        "            test_features.extend(x.reshape(x.shape[0], -1).numpy())\n",
        "            test_ids.extend([f.split('.')[0] for f in file_name])\n",
        "        final_test_preds = test_model.predict(test_features)\n",
        "\n",
        "    # --- 수정된 코드: 예측값을 텍스트 레이블로 변환 ---\n",
        "    # 0은 'normal', 1은 'dementia'로 매핑합니다.\n",
        "    label_map = {0: 'normal', 1: 'dementia'}\n",
        "    final_test_labels = [label_map[pred] for pred in final_test_preds]\n",
        "    # ----------------------------------------------------\n",
        "\n",
        "    # test_results.txt 파일 형식에 맞게 결과 저장\n",
        "    try:\n",
        "        with open(TEST_FILE_PATH, 'w') as f:\n",
        "            f.write(\"ID;Prediction\\n\")\n",
        "            for i, pred in enumerate(final_test_labels):\n",
        "                f.write(f\"{test_ids[i]};{pred}\\n\")\n",
        "\n",
        "        print(f\"Predictions saved to {TEST_FILE_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving predictions: {e}\")\n",
        "else:\n",
        "    print(\"WARNING: Test data not found or no models were trained. Skipping final prediction step.\")"
      ],
      "metadata": {
        "id": "0N65zlaG7QpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MczZKtYwzY0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pdrtd79nzY23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Gd2fdJ1zY6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "siYTIIGWyo_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJNoO6zPypCl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}